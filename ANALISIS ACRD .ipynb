{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f879f1a4-594c-4cb2-9b7d-aab685d3f330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d07be36-24cc-4c27-a727-521022226565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar las bases de datos\n",
    "df_acreditaciones = pd.read_excel(r\"C:\\Users\\wduran\\CLAROCHILE\\Nicoll Constanza Aguirre Diaz - dcabello\\Isa\\Bases análisis stock\\Analisis Acreditaciones.xlsx\")  \n",
    "df_ddss = pd.read_excel(r\"C:\\Users\\wduran\\CLAROCHILE\\Nicoll Constanza Aguirre Diaz - dcabello\\Isa\\Bases análisis stock\\Base acreditaciones DSS\\DSS\\DDSS 2023 base consolidada Ene-Sep.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7efd09-2a4a-43d8-8af5-804bc3f8e5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Realizar el join por el campo 'RUT'\n",
    "df_resultado = pd.merge(df_ddss, df_acreditaciones, how='inner', on='RUT')\n",
    "\n",
    "# Eliminar registros duplicados basados en HORA, MES, RUT\n",
    "df_resultado = df_resultado.drop_duplicates(subset=['HORA', 'MES', 'RUT'])\n",
    "\n",
    "# Guardar el resultado en un archivo Excel\n",
    "df_resultado.to_excel('resultado_final_DDSS.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b861a53-5520-4d99-b5f7-bb2f8aafe404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar las bases de datos\n",
    "\n",
    "df_fallaM = pd.read_csv(r\"C:\\Users\\wduran\\Downloads\\Falla_masiva_Consolidado.txt\", sep=\"\\t\", encoding='latin-1')\n",
    "df_acreditaciones = pd.read_excel(r\"C:\\Users\\wduran\\CLAROCHILE\\Nicoll Constanza Aguirre Diaz - dcabello\\Isa\\Bases análisis stock\\Analisis Acreditaciones.xlsx\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4842655-9f02-46fd-a881-0372403d6260",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Realizar el join por el campo 'rut'\n",
    "df_resultado = pd.merge(df_acreditaciones, df_fallaM, how='inner', on='RUT')\n",
    "\n",
    "# Crear un campo nuevo llamado 'Falla Masiva' con el conteo de repeticiones por mes\n",
    "df_resultado['falla_masiva'] = df_resultado.groupby(['RUT', 'mes']).transform('size')\n",
    "\n",
    "# Eliminar registros duplicados basados en HORA, MES, RUT\n",
    "df_resultado = df_resultado.drop_duplicates(subset=[ 'flag'])\n",
    "\n",
    "# Pivote sin cambiar el índice\n",
    "df_pivot = df_resultado.pivot_table(index=['RUT'], columns='mes', values='falla_masiva', aggfunc='size', fill_value=0)\n",
    "\n",
    "# Mostrar el resultado con RUTs en filas y nombres del mes en columnas\n",
    "print(df_pivot)\n",
    "\n",
    "df_pivot.reset_index(inplace=True)  # Agregar esta línea para resetear el índice y mostrar 'RUT' como columna\n",
    "\n",
    "df_pivot.to_excel('falla_masiva.xlsx', index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15265022-ea1a-4a95-b742-fc586185c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar las bases de datos\n",
    "df_acreditaciones = pd.read_excel(r\"C:\\Users\\wduran\\CLAROCHILE\\Nicoll Constanza Aguirre Diaz - dcabello\\Isa\\Bases análisis stock\\Analisis Acreditaciones.xlsx\")  \n",
    "df_Visita_Tec = pd.read_excel(r\"C:\\Users\\wduran\\Downloads\\visita tecnica.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9e7481-af16-4363-9eb1-03410ac78701",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Realizar el join por el campo 'rut'\n",
    "df_resultado = pd.merge(df_acreditaciones, df_Visita_Tec, how='inner', on='RUT')\n",
    "\n",
    "# Crear un campo nuevo llamado 'Visita_Tec' con el conteo de repeticiones por mes\n",
    "df_resultado['Visita_Tec'] = df_resultado.groupby(['RUT', 'mes']).transform('size')\n",
    "\n",
    "# Eliminar registros duplicados basados en HORA, MES, RUT\n",
    "df_resultado = df_resultado.drop_duplicates(subset=[ 'mes', 'RUT'])\n",
    "\n",
    "# Pivote sin cambiar el índice\n",
    "df_pivot = df_resultado.pivot_table(index=['RUT'], columns='mes', values='Visita_Tec', aggfunc='size', fill_value=0)\n",
    "\n",
    "# Mostrar el resultado con RUTs en filas y nombres del mes en columnas\n",
    "print(df_pivot)\n",
    "\n",
    "df_pivot.reset_index(inplace=True)  # Agregar esta línea para resetear el índice y mostrar 'RUT' como columna\n",
    "\n",
    "df_pivot.to_excel('resultado_Visita_Tec.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ee1f4f8-ef81-4788-941f-39340af37773",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Agregar periodo\n",
    "\n",
    "# Cargar la base de datos de salida final\n",
    "output_file = \"C:\\\\Users\\\\wduran\\\\Downloads\\\\Output Final Analisis de creditaciones.xlsx\"\n",
    "visita_tecnica_df = pd.read_excel(output_file, sheet_name=\"Visita_Tecnica\")\n",
    "\n",
    "# Eliminar espacios en blanco de la columna original y renombrarla\n",
    "visita_tecnica_df['RUT_ENTIDAD'] = visita_tecnica_df['RUT_ENTIDAD'].str.strip()\n",
    "visita_tecnica_df = visita_tecnica_df.rename(columns={'RUT_ENTIDAD': 'RUT_ENTIDAD'})\n",
    "\n",
    "# Cargar la base de datos de antigüedad\n",
    "antiguedad_file = \"C:\\\\Users\\\\wduran\\\\Downloads\\\\antiguedad.txt\"\n",
    "antiguedad_df = pd.read_csv(antiguedad_file, sep='\\t')\n",
    "\n",
    "# Eliminar espacios en blanco de la columna original y renombrarla\n",
    "antiguedad_df['RUT_ENTIDAD'] = antiguedad_df['RUT_ENTIDAD'].str.strip()\n",
    "antiguedad_df = antiguedad_df.rename(columns={'RUT_ENTIDAD': 'RUT_ENTIDAD'})\n",
    "\n",
    "# Realizar el join por el campo \"RUT_ENTIDAD\"\n",
    "merged_df = pd.merge(visita_tecnica_df, antiguedad_df, how='inner', on='RUT_ENTIDAD')\n",
    "\n",
    "# Guardar el resultado en un nuevo archivo Excel\n",
    "output_merged_file = \"C:\\\\Users\\\\wduran\\\\Downloads\\\\Output_Final_con_antiguedad.xlsx\"\n",
    "merged_df.to_excel(output_merged_file, index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb4379dd-0f60-45bf-9a7e-7b5dd50813ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cargar la base de datos de salida final\n",
    "output_file = \"C:\\\\Users\\\\wduran\\\\Downloads\\\\Output Final Analisis de creditaciones.xlsx\"\n",
    "Falla_Masiva_DF = pd.read_excel(output_file, sheet_name=\"Falla_Masiva\")\n",
    "\n",
    "# Eliminar espacios en blanco de la columna original y renombrarla\n",
    "Falla_Masiva_DF['RUT_ENTIDAD'] = Falla_Masiva_DF['RUT_ENTIDAD'].str.strip()\n",
    "Falla_Masiva_DF = Falla_Masiva_DF.rename(columns={'RUT_ENTIDAD': 'RUT_ENTIDAD'})\n",
    "\n",
    "# Cargar la base de datos de antigüedad\n",
    "antiguedad_file = \"C:\\\\Users\\\\wduran\\\\Downloads\\\\antiguedad.txt\"\n",
    "antiguedad_df = pd.read_csv(antiguedad_file, sep='\\t')\n",
    "\n",
    "# Eliminar espacios en blanco de la columna original y renombrarla\n",
    "antiguedad_df['RUT_ENTIDAD'] = antiguedad_df['RUT_ENTIDAD'].str.strip()\n",
    "antiguedad_df = antiguedad_df.rename(columns={'RUT_ENTIDAD': 'RUT_ENTIDAD'})\n",
    "\n",
    "# Realizar el join por el campo \"RUT_ENTIDAD\"\n",
    "merged_df = pd.merge(Falla_Masiva_DF, antiguedad_df, how='inner', on='RUT_ENTIDAD')\n",
    "\n",
    "# Guardar el resultado en un nuevo archivo Excel\n",
    "output_merged_file = \"C:\\\\Users\\\\wduran\\\\Downloads\\\\Output_Final_con_antiguedadFM.xlsx\"\n",
    "merged_df.to_excel(output_merged_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cc51395b-e82d-4e1e-9f5e-c4aee4146556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar la base de datos de salida final\n",
    "output_file = r\"C:\\Users\\wduran\\Downloads\\Output Final Analisis de creditaciones.xlsx\"\n",
    "Acrd_DSS_df = pd.read_excel(output_file, sheet_name=\"Acrd_DSS\")\n",
    "\n",
    "# Eliminar espacios en blanco de la columna original y renombrarla\n",
    "Acrd_DSS_df['RUT_ENTIDAD'] = Acrd_DSS_df['RUT_ENTIDAD'].str.strip()\n",
    "Acrd_DSS_df = Acrd_DSS_df.rename(columns={'RUT_ENTIDAD': 'RUT_ENTIDAD'})\n",
    "\n",
    "# Cargar la base de datos de antigüedad\n",
    "antiguedad_file = \"C:\\\\Users\\\\wduran\\\\Downloads\\\\antiguedad.txt\"\n",
    "antiguedad_df = pd.read_csv(antiguedad_file, sep='\\t')\n",
    "\n",
    "# Eliminar espacios en blanco de la columna original y renombrarla\n",
    "antiguedad_df['RUT_ENTIDAD'] = antiguedad_df['RUT_ENTIDAD'].str.strip()\n",
    "antiguedad_df = antiguedad_df.rename(columns={'RUT_ENTIDAD': 'RUT_ENTIDAD'})\n",
    "\n",
    "# Realizar el join por el campo \"RUT_ENTIDAD\"\n",
    "merged_df = pd.merge(Acrd_DSS_df, antiguedad_df, how='inner', on='RUT_ENTIDAD')\n",
    "\n",
    "# Guardar el resultado en un nuevo archivo Excel\n",
    "output_merged_file = \"C:\\\\Users\\\\wduran\\\\Downloads\\\\Output_Final_con_antiguedadDSS.xlsx\"\n",
    "merged_df.to_excel(output_merged_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd92e0eb-57ac-4a99-bcb7-b7eec59a2a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              RUT  abr-23  ago-23  ene-23  feb-23  jul-23  jun-23  mar-23  \\\n",
      "0      10001481-5     NaN     NaN     NaN     NaN     1.0     NaN     NaN   \n",
      "1      10001938-8     NaN     NaN     NaN     NaN     NaN     NaN     1.0   \n",
      "2      10002804-2     NaN     NaN     1.0     NaN     NaN     NaN     NaN   \n",
      "3      10002926-K     NaN     NaN     NaN     NaN     NaN     1.0     NaN   \n",
      "4      10003582-0     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "...           ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "23018   9997547-4     NaN     NaN     NaN     NaN     NaN     NaN     1.0   \n",
      "23019   9997853-8     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "23020   9998392-2     NaN     1.0     NaN     NaN     NaN     NaN     NaN   \n",
      "23021   9999260-3     NaN     NaN     NaN     NaN     NaN     NaN     1.0   \n",
      "23022   9999930-6     1.0     NaN     2.0     NaN     1.0     1.0     1.0   \n",
      "\n",
      "       may-23  sept-23   RUT_ENTIDAD  \n",
      "0         NaN      NaN  0010001481-5  \n",
      "1         NaN      2.0  0010001938-8  \n",
      "2         NaN      NaN  0010002804-2  \n",
      "3         NaN      NaN  0010002926-K  \n",
      "4         NaN      1.0  0010003582-0  \n",
      "...       ...      ...           ...  \n",
      "23018     NaN      NaN  0009997547-4  \n",
      "23019     1.0      NaN  0009997853-8  \n",
      "23020     1.0      NaN  0009998392-2  \n",
      "23021     NaN      NaN  0009999260-3  \n",
      "23022     1.0      NaN  0009999930-6  \n",
      "\n",
      "[23023 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print (Acrd_DSS_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a36ab3-0940-414b-9dca-b59cf28e775b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
